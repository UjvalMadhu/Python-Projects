{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2768113a-9d9b-4b87-b1cc-0e136d6aadf6",
   "metadata": {},
   "source": [
    "# American Sign Language Classification using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad680d03-5c15-456e-9a1d-646ffaa78333",
   "metadata": {},
   "source": [
    "This is a Convolutional Neural Network Implementation for the classification of American Sign Language.\n",
    "The implementation is based on an example shown from the \"Getting Started with Deep Learning Course\" offered by NVIDIA Deep Learning Institute\n",
    "\n",
    "**Author: Ujval Madhu**\\\n",
    "**C-Log: 01-22-2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b1dd5-4b32-4a3e-883e-89aa1a78fa49",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85cf9531-419a-4e42-9466-c987c1481174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"xpu\" if torch.xpu.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5682d0-15b5-478f-93d5-4005aa1992b0",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55f93e2f-60b5-4636-ab75-e24d613879dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/sign_mnist_train.csv\")    # Training Data Frame\n",
    "valid_df = pd.read_csv(\"data/sign_mnist_valid.csv\")    # Validation Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ae67b-899d-4906-9595-e61ec55aa8e4",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset as an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a4dcf0b-c587-4f1a-9784-0f87a6267437",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CH  = 1            # Input Image Channels = 1 B/W     \n",
    "IMG_HT  = 28           # Input Image Height   = 28 \n",
    "IMG_WT  = 28           # Input Image Width   = 28 \n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, base_df):\n",
    "        x_df = base_df.copy()                    # Copy the base class to avoid modifying the original dataset\n",
    "        y_df = x_df.pop('label')\n",
    "        x_df = x_df.values/255                   # Normalizing the dataset\n",
    "        x_df = x_df.reshape(-1, 1, 28, 28)       # Reshaping vector of size 1x784 into matrix 1x28x28\n",
    "        self.xs = torch.tensor(x_df).float().to(device)      # converting dataframes to tensors for Pytorch processing and moving to GPU if available\n",
    "        self.ys = torch.tensor(y_df).to(device)\n",
    "\n",
    "    def __getitem__(self, idx):                  # Required Method for Pytorch datasets: Returns a single data point and its label at given index\n",
    "        x = self.xs[idx]\n",
    "        y = self.ys[idx]\n",
    "        return x,y\n",
    "\n",
    "    def __len__(self):                           # Required Method for Pytorch datasets: Returns total number of samples\n",
    "        return len(self.xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3973a2-9706-44ca-9c83-8935d7a12100",
   "metadata": {},
   "source": [
    "### Creating DataLoaders for Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f562e552-7269-4263-b92d-ea86764c7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32;\n",
    "\n",
    "train_data = MyDataset(train_df)\n",
    "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "train_N = len(train_loader.dataset)\n",
    "\n",
    "valid_data = MyDataset(valid_df)\n",
    "valid_loader = DataLoader(valid_data, batch_size = BATCH_SIZE)\n",
    "valid_N = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8dcc6-cec0-461d-9823-87cb96fde555",
   "metadata": {},
   "source": [
    "### Creating The Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56564a36-e309-4481-89bb-91dcb65f43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 24           # j and z are not included as they require movement to classify so 26 - 2 = 24 alphabet classes\n",
    "kernel_size = 3          # standard and efficient kernel size 3x3 offers many advantages\n",
    "flattened_img_size = 75 * 3 * 3         # input dimension before flatten operation 75 channels of 3x3 matrices\n",
    "\n",
    "model = nn.Sequential(\n",
    "\n",
    "    # First Convolution\n",
    "    nn.Conv2d(IMG_CH, 25, kernel_size, stride = 1, padding = 1),        # Convolutional Layer with 25  3 x 3 kernels, Output Size = 25 x 28 x 28\n",
    "    nn.BatchNorm2d(25),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride = 2),                                        # Output Size = 25 x 14 x 14\n",
    "\n",
    "    # Second Convolution\n",
    "    nn.Conv2d(25, 50, kernel_size, stride = 1, padding = 1),            # Convolutional Layer with 50  3 x 3 kernels, Output Size = 50 x 14 x 14\n",
    "    nn.BatchNorm2d(50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.2),\n",
    "    nn.MaxPool2d(2, stride = 2),                                        # Output size = 50 x 7 x 7\n",
    "\n",
    "    # Third Convolution\n",
    "    nn.Conv2d(50, 75, kernel_size, stride = 1, padding = 1),            # Convolutional Layer with 75  3 x 3 kernels, Output Size = 75 x 7 x 7\n",
    "    nn.BatchNorm2d(75),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride = 2),                                        # Output size = 75 x 3 x 3\n",
    "\n",
    "    # Flatten to Dense Network\n",
    "    nn.Flatten(),                                                       # Flattens the 3D tensor of size 75 x 3 x 3 to a 1D tensor of size 75*3*3 = 675\n",
    "    nn.Linear(flattened_img_size, 512),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, n_classes)                                           # Dont need an activation function after as PyTorch's CrossEntropyLoss \n",
    "                                                                        # is numerically more when taking raw logits rather probabilities from a softmax \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c84258-a1db-483d-9b23-d6a966d1cbcf",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3aee594-be44-47e3-9994-6970e961c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f32b68-e1c1-4fbc-8713-62e7e13f76fa",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77d2e3e0-f474-4788-8a11-932764c2ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()              # We use the categorical cross entropy for calculating the loss function\n",
    "optimizer     = Adam(model.parameters())           # Adam Optimizer for minimizing the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cbff1ac-7c54-4231-8e4f-1a2c889d7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_accuracy(output, y, N):\n",
    "    \n",
    "    # selects index of highest value along dimension 1 = Predicted Value\n",
    "    pred = output.argmax(dim = 1, keepdim = True)\n",
    "    \n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    # y.view_as(pred) reshapes y to match pred's shape\n",
    "    # pred.eq(y) checks where predictions equal actual labels\n",
    "    # sum() counts how many correct predictions\n",
    "    # item() gets the actual number as a Python scalar\n",
    "    \n",
    "    return correct / N           # For adding accuracy of all batches per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5404dcd5-8258-4986-bab3-5826a90a7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()                                   # Sets Model to Training Mode\n",
    "    for x, y in train_loader:\n",
    "        output = model(x)                           # Forward Propagation\n",
    "        optimizer.zero_grad()                       # Clearing Previous Gradients\n",
    "        batch_loss = loss_function(output, y)       # Calculating Loss of the batch\n",
    "        batch_loss.backward()                       # Backpropagating\n",
    "        optimizer.step()                            # Weight Adjustment\n",
    "\n",
    "        loss += batch_loss.item()                          \n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "\n",
    "    print('Training Metrics: Loss: {:.4f}, Accuracy: {:.4f}'. format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc8a31bd-546e-4de7-ba4e-47738c7fbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()                                                 # Sets model to validation mode\n",
    "    with torch.no_grad():                                        # Turns off gradient computation\n",
    "        for x,y in valid_loader:\n",
    "            output = model(x)                                    # Forward pass\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "\n",
    "    print('Validation Metrics: Loss: {:.4f}, Accuracy: {:.4f}'. format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b610c59-2fc9-4547-9fe2-5901199fa864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training Metrics: Loss: 285.1434, Accuracy: 0.8994\n",
      "Validation Metrics: Loss: 37.6811, Accuracy: 0.9414\n",
      "Epoch: 1\n",
      "Training Metrics: Loss: 15.6213, Accuracy: 0.9955\n",
      "Validation Metrics: Loss: 33.3949, Accuracy: 0.9537\n",
      "Epoch: 2\n",
      "Training Metrics: Loss: 15.8443, Accuracy: 0.9949\n",
      "Validation Metrics: Loss: 31.6670, Accuracy: 0.9582\n",
      "Epoch: 3\n",
      "Training Metrics: Loss: 9.9800, Accuracy: 0.9968\n",
      "Validation Metrics: Loss: 41.4296, Accuracy: 0.9385\n",
      "Epoch: 4\n",
      "Training Metrics: Loss: 10.9114, Accuracy: 0.9962\n",
      "Validation Metrics: Loss: 49.7890, Accuracy: 0.9313\n",
      "Epoch: 5\n",
      "Training Metrics: Loss: 7.2893, Accuracy: 0.9973\n",
      "Validation Metrics: Loss: 21.4413, Accuracy: 0.9738\n",
      "Epoch: 6\n",
      "Training Metrics: Loss: 9.9572, Accuracy: 0.9966\n",
      "Validation Metrics: Loss: 17.6262, Accuracy: 0.9788\n",
      "Epoch: 7\n",
      "Training Metrics: Loss: 2.3523, Accuracy: 0.9992\n",
      "Validation Metrics: Loss: 20.3253, Accuracy: 0.9739\n",
      "Epoch: 8\n",
      "Training Metrics: Loss: 7.4049, Accuracy: 0.9976\n",
      "Validation Metrics: Loss: 22.6906, Accuracy: 0.9773\n",
      "Epoch: 9\n",
      "Training Metrics: Loss: 2.7202, Accuracy: 0.9994\n",
      "Validation Metrics: Loss: 22.0381, Accuracy: 0.9777\n",
      "Epoch: 10\n",
      "Training Metrics: Loss: 6.1191, Accuracy: 0.9976\n",
      "Validation Metrics: Loss: 19.2506, Accuracy: 0.9756\n",
      "Epoch: 11\n",
      "Training Metrics: Loss: 8.5590, Accuracy: 0.9970\n",
      "Validation Metrics: Loss: 32.2621, Accuracy: 0.9532\n",
      "Epoch: 12\n",
      "Training Metrics: Loss: 4.1604, Accuracy: 0.9986\n",
      "Validation Metrics: Loss: 11.7338, Accuracy: 0.9841\n",
      "Epoch: 13\n",
      "Training Metrics: Loss: 0.6834, Accuracy: 0.9997\n",
      "Validation Metrics: Loss: 25.0991, Accuracy: 0.9695\n",
      "Epoch: 14\n",
      "Training Metrics: Loss: 0.2764, Accuracy: 0.9999\n",
      "Validation Metrics: Loss: 23.5772, Accuracy: 0.9704\n",
      "Epoch: 15\n",
      "Training Metrics: Loss: 11.7485, Accuracy: 0.9969\n",
      "Validation Metrics: Loss: 16.2818, Accuracy: 0.9856\n",
      "Epoch: 16\n",
      "Training Metrics: Loss: 0.6547, Accuracy: 0.9999\n",
      "Validation Metrics: Loss: 14.3135, Accuracy: 0.9795\n",
      "Epoch: 17\n",
      "Training Metrics: Loss: 5.7668, Accuracy: 0.9980\n",
      "Validation Metrics: Loss: 24.9219, Accuracy: 0.9721\n",
      "Epoch: 18\n",
      "Training Metrics: Loss: 3.8108, Accuracy: 0.9987\n",
      "Validation Metrics: Loss: 10.9878, Accuracy: 0.9886\n",
      "Epoch: 19\n",
      "Training Metrics: Loss: 3.0695, Accuracy: 0.9989\n",
      "Validation Metrics: Loss: 9.1669, Accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'. format(epoch))\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a651db-3bec-43fb-b7cd-f166d0fb6c42",
   "metadata": {},
   "source": [
    "### Shutting down IPython Kernel (Python Interpreter in the Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b44a3f84-c8ee-4b82-9c2b-5384263bc04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21693769-b770-4834-99a6-f41fdefe600b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
